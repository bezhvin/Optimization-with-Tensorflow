{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bezhvin/Optimization-with-Tensorflow/blob/main/SimpleExampleNoConstraint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "28fac8df",
      "metadata": {
        "id": "28fac8df"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from six.moves import xrange\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Math, Latex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce91f13c",
      "metadata": {
        "id": "ce91f13c"
      },
      "outputs": [],
      "source": [
        "#!pip install git+https://github.com/google-research/tensorflow_constrained_optimization\n",
        "#import tensorflow_constrained_optimization as tfco"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "763f79dd",
      "metadata": {
        "id": "763f79dd"
      },
      "source": [
        "### simple non constrained opttimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b18ef4",
      "metadata": {
        "id": "54b18ef4"
      },
      "source": [
        "Let's start with a simple example of fitting some coefficients for a quadratic function:\n",
        "$$y = ax^2 + bx+c$$\n",
        "This is basically a simple plynomial fitting and can be done mathematically as it is a convex optimization. But for the sake of illustration let's assume we want to the find proper prameters ${a,b,c}$ via some iterative gradient based optimization.\n",
        "Assuming the ground truth parameters are ${a=3, b=.5, and\\ c=4}$, we have\n",
        "$$y = 3x^2 + .5x+4$$\n",
        "Let's generate the training data with 50 samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e60843e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "9e60843e",
        "outputId": "ed924bf3-31cf-49dd-cb6f-7e7188e438c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'X')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "training_size = 50\n",
        "y_clean = lambda x: 3*x**2 + .5*x + 4 \n",
        "\n",
        "## randomly generating X\n",
        "X= np.random.uniform(low=-2, high=2,size=training_size).astype(np.float32) ## input \n",
        "## and then generating the corresponding y\n",
        "y = y_clean(X) + np.random.normal(size=training_size).astype(np.float32) # output --> we added some noise to make it more realistic\n",
        "## how does it look like?\n",
        "plt.scatter(X, y)\n",
        "plt.ylabel('y'); plt.xlabel('X')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc04250e",
      "metadata": {
        "id": "cc04250e"
      },
      "source": [
        "First, it is helpful to rewrite the problem in a matrix multiplication format \n",
        "$$y = AX $$\n",
        "this helps the code to be cleaner and is more inline wit what tensorflow expect. In general we know computers are good at matrix multiplication so we always should try to frame our problems in in this way!\n",
        "Thus, we can rewrite it as:\n",
        "\n",
        "$$\n",
        "y = \\begin{bmatrix}  \n",
        "a & b & c  \n",
        "\\end{bmatrix} \n",
        "\\begin{bmatrix}  \n",
        "x^2\\\\  \n",
        "x\\\\  \n",
        "1\\\\  \n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "52d00341",
      "metadata": {
        "id": "52d00341"
      },
      "outputs": [],
      "source": [
        "# y=AX\n",
        "X_matrix = np.array([X**2, X, np.ones(X.size)]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "48b39f74",
      "metadata": {
        "id": "48b39f74"
      },
      "outputs": [],
      "source": [
        "# making constant tensors for the training data\n",
        "y_ground_truth = tf.constant(y, dtype=tf.float32)\n",
        "X_ground_truth = tf.constant(X_matrix, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6c6ff572",
      "metadata": {
        "id": "6c6ff572"
      },
      "outputs": [],
      "source": [
        "# initializing the parameters a,b,and c as tensor variables\n",
        "# this is the variable which will be updated during the optimization\n",
        "weights = tf.Variable(tf.random_normal_initializer()(shape=[3], dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "13bbebd8",
      "metadata": {
        "id": "13bbebd8"
      },
      "outputs": [],
      "source": [
        "# the estimated y (or prediction for y) using the weights we want to optimize\n",
        "y_prediction = tf.tensordot(X_ground_truth, weights, axes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3585d002",
      "metadata": {
        "id": "3585d002"
      },
      "source": [
        "To optimize the parameters we need to define an objective function. actually we optimize the parameters with respect to this objective function. In our example, the least square could be helpful:\n",
        "$$ mean((y - y_{prediction})^2) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b9a78197",
      "metadata": {
        "id": "b9a78197"
      },
      "outputs": [],
      "source": [
        "## tensorflow has already made many of the known objective functions available, e.g. in tf.compat.v1.losses\n",
        "## but you may still wrtie down the objective formula yourself. Both ways are shown below\n",
        "def objective():\n",
        "    y_prediction = tf.tensordot(X_ground_truth, weights, axes=1)\n",
        "    return tf.math.reduce_mean((y_ground_truth - y_prediction)**2)\n",
        "#     return tf.compat.v1.losses.mean_squared_error(labels=y_ground_truth,\n",
        "#                                                  predictions=y_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e448f57d",
      "metadata": {
        "id": "e448f57d"
      },
      "source": [
        "There are many gradient descent optimization algorithms and fortunately almost all are available in tensorflow. The choice of the algorithm depends on the task. In our example, all would work properly (some faster some slower)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dd6a290c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd6a290c",
        "outputId": "7244325f-987b-403a-a043-4016e52cad0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the parameters are: [a, b, c] = [2.9300997 0.6277682 4.034717 ]\n"
          ]
        }
      ],
      "source": [
        "# optimization\n",
        "optimizer = tf.keras.optimizers.Adagrad(learning_rate=1.0)\n",
        "var_list=[weights]\n",
        "for ii in range(100):\n",
        "    optimizer.minimize(objective, var_list=var_list)\n",
        "    #print(weights.numpy()) --> activate if you want to see how the parameters get updated\n",
        "print(f'the parameters are: [a, b, c] = {(weights.numpy())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a90565",
      "metadata": {
        "id": "98a90565"
      },
      "source": [
        "These parameters are close to the ground truth coefficients, right? the small difference is due to the noise we added to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161aeb34",
      "metadata": {
        "id": "161aeb34"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}